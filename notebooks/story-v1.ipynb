{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsh_axMLnqsY",
        "outputId": "ae08c930-148f-4e46-9d75-0e6a87f85f68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "Aborted!\n"
          ]
        }
      ],
      "source": [
        "!wandb login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsvsYVGF4OHF",
        "outputId": "5c6ad76f-7a04-4ea3-b4f8-93fd5464ad12"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found cached dataset parquet (/home/recurrent/.cache/huggingface/datasets/roneneldan___parquet/roneneldan--TinyStories-6ac769f186d7da53/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
            "100%|██████████| 2/2 [00:00<00:00, 91.74it/s]\n",
            "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=temp.txt --model_prefix=stories --vocab_size=7600 --character_coverage=1.0 --model_type=unigram\n",
            "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
            "trainer_spec {\n",
            "  input: temp.txt\n",
            "  input_format: \n",
            "  model_prefix: stories\n",
            "  model_type: UNIGRAM\n",
            "  vocab_size: 7600\n",
            "  self_test_sample_size: 0\n",
            "  character_coverage: 1\n",
            "  input_sentence_size: 0\n",
            "  shuffle_input_sentence: 1\n",
            "  seed_sentencepiece_size: 1000000\n",
            "  shrinking_factor: 0.75\n",
            "  max_sentence_length: 4192\n",
            "  num_threads: 16\n",
            "  num_sub_iterations: 2\n",
            "  max_sentencepiece_length: 16\n",
            "  split_by_unicode_script: 1\n",
            "  split_by_number: 1\n",
            "  split_by_whitespace: 1\n",
            "  split_digits: 0\n",
            "  pretokenization_delimiter: \n",
            "  treat_whitespace_as_suffix: 0\n",
            "  allow_whitespace_only_pieces: 0\n",
            "  required_chars: \n",
            "  byte_fallback: 0\n",
            "  vocabulary_output_piece_score: 1\n",
            "  train_extremely_large_corpus: 0\n",
            "  hard_vocab_limit: 1\n",
            "  use_all_vocab: 0\n",
            "  unk_id: 0\n",
            "  bos_id: 1\n",
            "  eos_id: 2\n",
            "  pad_id: -1\n",
            "  unk_piece: <unk>\n",
            "  bos_piece: <s>\n",
            "  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "successfully trained sp\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "eos_piece: </s>\n",
            "  pad_piece: <pad>\n",
            "  unk_surface:  ⁇ \n",
            "  enable_differential_privacy: 0\n",
            "  differential_privacy_noise_level: 0\n",
            "  differential_privacy_clipping_threshold: 0\n",
            "}\n",
            "normalizer_spec {\n",
            "  name: nmt_nfkc\n",
            "  add_dummy_prefix: 1\n",
            "  remove_extra_whitespaces: 1\n",
            "  escape_whitespaces: 1\n",
            "  normalization_rule_tsv: \n",
            "}\n",
            "denormalizer_spec {}\n",
            "trainer_interface.cc(351) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
            "trainer_interface.cc(183) LOG(INFO) Loading corpus: temp.txt\n",
            "trainer_interface.cc(407) LOG(INFO) Loaded all 40791 sentences\n",
            "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <unk>\n",
            "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <s>\n",
            "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: </s>\n",
            "trainer_interface.cc(428) LOG(INFO) Normalizing sentences...\n",
            "trainer_interface.cc(537) LOG(INFO) all chars count=6771738\n",
            "trainer_interface.cc(558) LOG(INFO) Alphabet size=89\n",
            "trainer_interface.cc(559) LOG(INFO) Final character coverage=1\n",
            "trainer_interface.cc(591) LOG(INFO) Done! preprocessed 40743 sentences.\n",
            "unigram_model_trainer.cc(222) LOG(INFO) Making suffix array...\n",
            "unigram_model_trainer.cc(226) LOG(INFO) Extracting frequent sub strings... node_num=3904733\n",
            "unigram_model_trainer.cc(274) LOG(INFO) Initialized 27973 seed sentencepieces\n",
            "trainer_interface.cc(597) LOG(INFO) Tokenizing input sentences with whitespace: 40743\n",
            "trainer_interface.cc(608) LOG(INFO) Done! 27234\n",
            "unigram_model_trainer.cc(564) LOG(INFO) Using 27234 sentences for EM training\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=12570 obj=9.44774 num_tokens=55782 num_tokens/piece=4.43771\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=8932 obj=7.38319 num_tokens=55966 num_tokens/piece=6.26579\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=8359 obj=7.30539 num_tokens=56114 num_tokens/piece=6.713\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=8340 obj=7.29941 num_tokens=56137 num_tokens/piece=6.73106\n",
            "trainer_interface.cc(686) LOG(INFO) Saving model: stories.model\n",
            "trainer_interface.cc(698) LOG(INFO) Saving vocabs: stories.vocab\n"
          ]
        }
      ],
      "source": [
        "# Data\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "from datasets import load_dataset\n",
        "import sentencepiece as spm\n",
        "import os\n",
        "\n",
        "vocab_size = 7600 # english has 26 * 2 + punctuation\n",
        "\n",
        "dataset = load_dataset(\"roneneldan/TinyStories\")\n",
        "\n",
        "train_dataset = dataset['train'][:8000]\n",
        "\n",
        "validation_dataset = dataset['validation'][:2000]\n",
        "text_data = [entry for entry in train_dataset['text']]\n",
        "validation_data = [entry for entry in validation_dataset['text']]\n",
        "\n",
        "text_data_str = '\\n'.join(text_data)\n",
        "with open('temp.txt', 'w', encoding='utf-8') as f:\n",
        "    f.write(text_data_str)\n",
        "\n",
        "spm.SentencePieceTrainer.train(\n",
        "        f'--input=temp.txt --model_prefix=stories --vocab_size={vocab_size} --character_coverage=1.0 --model_type=unigram'\n",
        "    )\n",
        "sp = spm.SentencePieceProcessor(model_file='./stories.model')\n",
        "\n",
        "print('successfully trained sp')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "oUdtO0ij47pZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.optim import Adam\n",
        "from collections import Counter\n",
        "import json\n",
        "\n",
        "PAD_TOKEN = sp.piece_to_id('<unk>')\n",
        "batch_size = 16\n",
        "\n",
        "def target_story_to_tensor(story):\n",
        "    tokens = torch.tensor(sp.encode_as_ids(story) + [sp.piece_to_id('</s>')], dtype=torch.long)\n",
        "    return tokens\n",
        "\n",
        "def input_story_to_tensor(story):\n",
        "    tokens = torch.tensor([sp.piece_to_id('<s>')] + sp.encode_as_ids(story), dtype=torch.long)\n",
        "    return tokens\n",
        "\n",
        "class StoryDataset(Dataset):\n",
        "    def __init__(self, stories):\n",
        "        self.stories = stories\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.stories)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        story = self.stories[idx]\n",
        "        return input_story_to_tensor(story), target_story_to_tensor(story)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    inputs, targets = zip(*batch)\n",
        "    inputs = pad_sequence(inputs, batch_first=True, padding_value=PAD_TOKEN)\n",
        "    targets = pad_sequence(targets, batch_first=True, padding_value=PAD_TOKEN)\n",
        "    return inputs, targets\n",
        "\n",
        "# Create dataset and dataloader\n",
        "dataset = StoryDataset(text_data)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "val_data = StoryDataset(validation_data)\n",
        "val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFjr-EAr4Q4l",
        "outputId": "0d3f0faa-39bf-4f42-f95e-a0318faf6b90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8000\n",
            "2000\n"
          ]
        }
      ],
      "source": [
        "print(len(text_data))\n",
        "print(len(validation_data))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NK3oHTvI5RqC",
        "outputId": "62d75d39-7fe8-48ef-a335-e677b13226f7"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "d_model = 256\n",
        "dropout = 0.1 # 10% chance that any given neuron will be dropped out\n",
        "n_heads = 8\n",
        "n_layer = 8\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# device = 'cpu'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Fr6ZPtcC5SRo"
      },
      "outputs": [],
      "source": [
        "def create_mask(seq):\n",
        "    seq_len = seq.size(1)\n",
        "    mask = torch.triu(torch.ones(seq_len, seq_len, device=seq.device), diagonal=1).bool()\n",
        "    return mask\n",
        "\n",
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model):\n",
        "        super(TransformerDecoder, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_encoder = PositionalEncoding(d_model)\n",
        "\n",
        "        self.blocks = nn.Sequential(\n",
        "            *[Block(n_heads) for _ in range(n_layer)]\n",
        "        )\n",
        "        self.fc = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # print('Im here')\n",
        "        input = self.embedding(input)\n",
        "        input = self.pos_encoder(input)\n",
        "        blocks_output = self.blocks(input)\n",
        "\n",
        "        logits = self.fc(blocks_output)\n",
        "        return logits\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, n_heads):\n",
        "        super().__init__()\n",
        "        head_size = d_model // n_heads\n",
        "        self.multi_head_attention = MultiHeadAttention(n_heads, head_size)\n",
        "        self.ffwd = nn.Sequential(\n",
        "            nn.Linear(d_model, 4*d_model), # expanding and contracting the model for it to learn more intricate patterns\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(4*d_model, d_model)\n",
        "        )\n",
        "\n",
        "        self.ln1 = nn.LayerNorm(d_model)\n",
        "        self.ln2 = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # actually doing residual connection here by attn1_output + input\n",
        "        # print('im in block forward')\n",
        "        x = x + self.multi_head_attention(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        # print('Block shape', x.shape)\n",
        "        return x\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([SelfAttention(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(d_model, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mask = create_mask(x).to(x.device)\n",
        "        # print('im in multiheadattention')\n",
        "        out = torch.cat([h(x, x, x, mask) for h in self.heads], dim=-1) # can parallelize it\n",
        "        # print('multiheadattention out.shape', out.shape)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        # here not printing\n",
        "        # print('dropout out.shape', out.shape)\n",
        "        return out\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, head_size):\n",
        "        super(SelfAttention, self).__init__()\n",
        "        self.query = nn.Linear(d_model, head_size, bias=False)\n",
        "        self.key = nn.Linear(d_model, head_size, bias=False)\n",
        "        self.value = nn.Linear(d_model, head_size, bias=False)\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        # print('im in self attention')\n",
        "        # print('head_size')\n",
        "        q = self.query(query)\n",
        "        k = self.key(key)\n",
        "        v = self.value(value)\n",
        "\n",
        "        # print('q.shape', q.shape)\n",
        "        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_model)\n",
        "        # print('scores.shape', scores.shape)\n",
        "        # print('mask', mask)\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask, float('-inf'))\n",
        "\n",
        "        attention_weights = torch.nn.functional.softmax(scores, dim=-1)\n",
        "        # print('attention_weights', attention_weights.shape)\n",
        "        # print('v', v.shape)\n",
        "        output = torch.matmul(attention_weights, v)\n",
        "        # print('output.shape of selfattention', output.shape)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_checkpoint(epoch, model, optimizer, filename=\"checkpoint.pth.tar\"):\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "    }, filename)\n",
        "\n",
        "def load_checkpoint(filename=\"checkpoint.pth.tar\"):\n",
        "    checkpoint = torch.load(filename)\n",
        "    return checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272,
          "referenced_widgets": [
            "5ed0772ee15c4be995eb9afd1f62669f",
            "b1e30092f33b4150b43762891d7ed475",
            "30701543fdd6437087e008f0eb0b9178",
            "9d45f30a410d41d2bc6e71ba4ec0bfec",
            "6c1a67da60834a748ced4aac4887702d",
            "25530b3ed760476b842a459408bff602",
            "25622a07757b454a9b02b4baf201e2ba",
            "473ea88059a34441ac518432dc837567"
          ]
        },
        "id": "NxjQ62ud5T7r",
        "outputId": "53d8cd11-186a-48b8-8ba6-28823f280d9e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.8"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/recurrent/tinier-world/wandb/run-20230817_150012-8r22tsbp</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/serena_chan/story_generator/runs/8r22tsbp' target=\"_blank\">experiment-8-embedding-256-mixed-precision</a></strong> to <a href='https://wandb.ai/serena_chan/story_generator' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/serena_chan/story_generator' target=\"_blank\">https://wandb.ai/serena_chan/story_generator</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/serena_chan/story_generator/runs/8r22tsbp' target=\"_blank\">https://wandb.ai/serena_chan/story_generator/runs/8r22tsbp</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Epoch 1/30 - Loss: 4.0466\n",
            "val Epoch 1/30 - Loss: 3.5273\n",
            "train Epoch 2/30 - Loss: 3.1992\n",
            "val Epoch 2/30 - Loss: 3.0645\n",
            "train Epoch 3/30 - Loss: 2.8545\n",
            "val Epoch 3/30 - Loss: 2.7305\n",
            "train Epoch 4/30 - Loss: 2.6342\n",
            "val Epoch 4/30 - Loss: 2.4492\n",
            "train Epoch 5/30 - Loss: 2.4737\n",
            "val Epoch 5/30 - Loss: 2.3223\n",
            "train Epoch 6/30 - Loss: 2.3450\n",
            "val Epoch 6/30 - Loss: 2.5000\n",
            "train Epoch 7/30 - Loss: 2.2417\n",
            "val Epoch 7/30 - Loss: 2.4707\n",
            "train Epoch 8/30 - Loss: 2.1550\n",
            "val Epoch 8/30 - Loss: 2.2637\n",
            "train Epoch 9/30 - Loss: 2.0821\n",
            "val Epoch 9/30 - Loss: 2.3438\n",
            "train Epoch 10/30 - Loss: 2.0172\n",
            "val Epoch 10/30 - Loss: 2.2090\n",
            "train Epoch 11/30 - Loss: 1.9614\n",
            "val Epoch 11/30 - Loss: 2.1309\n",
            "train Epoch 12/30 - Loss: 1.9099\n",
            "val Epoch 12/30 - Loss: 1.8193\n",
            "train Epoch 13/30 - Loss: 1.8627\n",
            "val Epoch 13/30 - Loss: 2.0059\n",
            "train Epoch 14/30 - Loss: 1.8165\n",
            "val Epoch 14/30 - Loss: 1.9209\n",
            "train Epoch 15/30 - Loss: 1.7801\n",
            "val Epoch 15/30 - Loss: 1.8467\n",
            "train Epoch 16/30 - Loss: 1.7390\n",
            "val Epoch 16/30 - Loss: 1.8857\n",
            "train Epoch 17/30 - Loss: 1.7049\n",
            "val Epoch 17/30 - Loss: 1.7490\n",
            "train Epoch 18/30 - Loss: 1.6696\n",
            "val Epoch 18/30 - Loss: 1.7822\n",
            "train Epoch 19/30 - Loss: 1.6398\n",
            "val Epoch 19/30 - Loss: 1.8672\n",
            "train Epoch 20/30 - Loss: 1.6088\n",
            "val Epoch 20/30 - Loss: 1.7217\n",
            "train Epoch 21/30 - Loss: 1.5791\n",
            "val Epoch 21/30 - Loss: 1.7676\n",
            "train Epoch 22/30 - Loss: 1.5511\n",
            "val Epoch 22/30 - Loss: 1.6270\n",
            "train Epoch 23/30 - Loss: 1.5288\n",
            "val Epoch 23/30 - Loss: 1.6992\n",
            "train Epoch 24/30 - Loss: 1.5023\n",
            "val Epoch 24/30 - Loss: 1.5254\n",
            "train Epoch 25/30 - Loss: 1.4788\n",
            "val Epoch 25/30 - Loss: 1.4180\n",
            "train Epoch 26/30 - Loss: 1.4548\n",
            "val Epoch 26/30 - Loss: 1.5010\n",
            "train Epoch 27/30 - Loss: 1.4360\n",
            "val Epoch 27/30 - Loss: 1.5342\n",
            "train Epoch 28/30 - Loss: 1.4157\n",
            "val Epoch 28/30 - Loss: 1.4971\n",
            "train Epoch 29/30 - Loss: 1.3966\n",
            "val Epoch 29/30 - Loss: 1.4619\n",
            "train Epoch 30/30 - Loss: 1.3755\n",
            "val Epoch 30/30 - Loss: 1.6025\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>time_taken_epoch_train</td><td>▃█▅▄▅▅▁▇▃▄▄▄▄▄▅▂▃▅▂▄▆▅▄▄▄▅▅▁▃▆</td></tr><tr><td>time_taken_epoch_val</td><td>▇▆▅▃▆▄▇▄▆▇▇▅▃▆▄▅▅▂█▅▃▃▃▅▄▁▆▅▄▅</td></tr><tr><td>train_loss</td><td>█▇▆▅▄▅▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▁▂▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▆▆▅▄▄▄▅▄▄▄▄▄▃▃▂▃▃▃▂▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>29</td></tr><tr><td>time_taken_epoch_train</td><td>68.08528</td></tr><tr><td>time_taken_epoch_val</td><td>5.15923</td></tr><tr><td>train_loss</td><td>1.37548</td></tr><tr><td>val_loss</td><td>1.60254</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">experiment-8-embedding-256-mixed-precision</strong> at: <a href='https://wandb.ai/serena_chan/story_generator/runs/8r22tsbp' target=\"_blank\">https://wandb.ai/serena_chan/story_generator/runs/8r22tsbp</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230817_150012-8r22tsbp/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import wandb\n",
        "import time\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "num_epochs = 30\n",
        "lr = 0.001\n",
        "\n",
        "name = \"experiment-8-embedding-256-mixed-precision\"\n",
        "\n",
        "# Define the model, optimizer, and loss\n",
        "decoder = TransformerDecoder(vocab_size, d_model).to(device)\n",
        "optimizer = Adam(decoder.parameters(), lr=lr)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "num_params = sum(p.numel() for p in decoder.parameters())\n",
        "\n",
        "# Training loop\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss(ignore_index=PAD_TOKEN)\n",
        "\n",
        "run = wandb.init(project=\"story_generator\", name=name,\n",
        "                 config={\"optimizer\": \"Adam\", \"lr\": lr, \"epochs\": num_epochs, \"batch_size\": batch_size, \"device\": device, \"vocab_size\": vocab_size, \"dataloader\": len(text_data), \"n_heads\": n_heads, \"n_layer\": n_layer, \"d_model\": d_model, \"num_params\": num_params})\n",
        "\n",
        "wandb.watch(decoder)\n",
        "\n",
        "patience = 5\n",
        "stopping_counter = 0\n",
        "train_iteration = 0\n",
        "val_iteration = 0\n",
        "scaler = GradScaler()\n",
        "for epoch in range(num_epochs):\n",
        "    decoder.train()\n",
        "    train_loss = 0.0\n",
        "    start_time = time.time()\n",
        "    for inputs, targets in dataloader:\n",
        "        # start_time = time.time()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        with autocast():t\n",
        "            outputs = decoder(inputs)\n",
        "            torch.cuda.empty_cache()\n",
        "            loss = criterion(outputs.view(-1, vocab_size), targets.view(-1))\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        train_iteration += 1\n",
        "\n",
        "        # end_time = time.time()\n",
        "        # iteration_duration = (end_time - start_time)\n",
        "        wandb.log({\"train_loss\": loss.item()})\n",
        "\n",
        "    end_time = time.time()  # <-- Record the end time\n",
        "    epoch_duration = end_time - start_time  # <-- Calculate epoch duration\n",
        "\n",
        "    avg_loss_train = train_loss / len(dataloader)\n",
        "    print(f\"train Epoch {epoch + 1}/{num_epochs} - Loss: {avg_loss_train:.4f}\")\n",
        "    wandb.log({\"epoch\": epoch, \"train_loss\": avg_loss_train, \"time_taken_epoch_train\": epoch_duration})\n",
        "\n",
        "\n",
        "    # validation loop\n",
        "    decoder.eval()\n",
        "    val_loss = 0.0\n",
        "    best_val_loss = float('inf')\n",
        "    start_time = time.time()\n",
        "    with torch.no_grad():\n",
        "      for val_inputs, val_targets in val_dataloader:\n",
        "        # start_time = time.time()\n",
        "        val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
        "        val_outputs = decoder(val_inputs)\n",
        "        loss = criterion(outputs.view(-1, vocab_size), targets.view(-1))\n",
        "        val_loss += loss.item()\n",
        "        \n",
        "        val_iteration += 1\n",
        "        end_time = time.time()\n",
        "        iteration_duration = (end_time - start_time)\n",
        "        wandb.log({\"val_loss\": loss.item()})\n",
        "        \n",
        "    end_time = time.time()\n",
        "    avg_val_loss = val_loss / len(val_dataloader)\n",
        "    epoch_duration = end_time - start_time\n",
        "    wandb.log({\"epoch\": epoch, \"val_loss\": avg_val_loss, \"time_taken_epoch_val\": epoch_duration})\n",
        "    avg_loss_val = val_loss / len(val_dataloader)\n",
        "    print(f\"val Epoch {epoch + 1}/{num_epochs} - Loss: {avg_loss_val:.4f}\")\n",
        "    \n",
        "    \n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        save_checkpoint(epoch, decoder, optimizer, \"best_checkpoint.pth.tar\")\n",
        "        stopping_counter = 0\n",
        "    else:\n",
        "        stopping_counter += 1\n",
        "        if stopping_counter >= patience:\n",
        "            print(\"Early stopping triggered\")\n",
        "            break\n",
        "\n",
        "# Save your model.\n",
        "model_path = f'cuda-train-50000-{name}.pth'\n",
        "\n",
        "torch.save(decoder.state_dict(), model_path)\n",
        "artifact = wandb.Artifact('model', type='model')\n",
        "artifact.add_file(model_path)\n",
        "run.log_artifact(artifact)\n",
        "run.finish()\n",
        "\n",
        "\n",
        "# torch.save(decoder.state_dict(), model_path)\n",
        "# wandb.save(model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAEu94EjNr7T",
        "outputId": "3f8b37dd-f713-4ef7-ffaf-9fa63d879c30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vocab_size 7600\n",
            "[47, 30, 51, 8, 37, 4, 39, 9, 8, 36, 56, 65, 53, 26, 3, 14, 84, 7, 58, 154, 22, 6, 107, 3, 46, 25, 4, 20, 44, 8, 2202, 592, 83, 12, 3, 17, 2202, 9, 41, 295, 5, 31, 8, 295, 890, 640, 3, 26, 61, 7, 443, 6, 2202, 4, 50, 10, 257, 103, 3, 26, 9, 119, 5, 145, 13, 40, 187, 102, 7, 120, 3, 169, 4, 20, 44, 8, 2202, 592, 770, 3, 17, 2202, 81, 26, 102, 9, 486, 5, 6, 2202, 19, 4, 11, 692, 79, 34, 119, 4, 36, 3923, 75, 26, 289, 4, 11, 115, 516, 179, 1718, 3, 57, 226, 13, 40, 187, 175, 7, 443, 10, 49, 17, 2202, 257, 103, 5, 26, 9, 119, 3, 26, 31, 516, 12, 1718, 5, 173, 13, 40, 368, 372, 3, 14, 31, 7, 96, 6, 2202, 3]\n",
            "Once upon a time, there was a little girl named Lily. She loved to play outside in the park. One day, she saw a pigeon flying around her. The pigeon was very pretty and had a pretty purple hat. Lily wanted to catch the pigeon, but it flew away. Lily was sad and didn't know what to do. Suddenly, she saw a pigeon flying nearby. The pigeon asked Lily what was wrong and the pigeon said, \"Why are you sad, little guy?\" Lily replied, \"I lost my scarf. I don't know how to catch it.\" The pigeon flew away and Lily was sad. Lily had lost her scarf and couldn't fly anymore. She had to help the pigeon.\n"
          ]
        }
      ],
      "source": [
        "print('vocab_size', vocab_size)\n",
        "\n",
        "def generate_story(model, device, max_length=200):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        input_token = sp.piece_to_id('<s>')\n",
        "        output_sequence = [input_token] # we'll always get the same name because we are using the same model and the same starter token\n",
        "\n",
        "        for i in range(max_length):\n",
        "            input_tensor = torch.tensor([output_sequence]).long().to(device) # Move tensor to the correct device\n",
        "            logit_output = model(input_tensor)\n",
        "\n",
        "            softmax = nn.Softmax(dim=-1)\n",
        "            softmax_output = softmax(logit_output)\n",
        "            # Taking the token with the highest probability for prediction\n",
        "            predicted_token = softmax_output[0, -1, :].argmax().item()\n",
        "\n",
        "            # Break if we predict the end-of-string token\n",
        "            if predicted_token == sp.piece_to_id('</s>'):\n",
        "                break\n",
        "\n",
        "            output_sequence.append(predicted_token)\n",
        "\n",
        "        # Convert token IDs back to strings\n",
        "        print(output_sequence[1:])\n",
        "        generated_story= sp.decode_ids(output_sequence[1:])\n",
        "\n",
        "    return generated_story\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "generated_story = generate_story(decoder.to(device), device) # Make sure your model is on the correct device\n",
        "print(generated_story)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407,
          "referenced_widgets": [
            "8725892a81f64a538c20d84c033eec1d",
            "d5013a329b524d4ab70eec3d410daca5",
            "b6dee90914fd4aecac4dfba8a3f721e8",
            "93e9ba02298941d2b6cd44f443d10d8c",
            "4478b438ff024eb3b4e913a046927810",
            "7b0fe0f5e41a47d98b92fff0b833f513",
            "beba080cfc9c4da3a896bd4f2afc1a92",
            "55c55702847f4c16963f1a04175cbf55",
            "99cfeddc6a9c4303a9b2c6d1b5bb513e",
            "b4690013074e4f07a4ea1630c719d38e",
            "6b385ef65bfe4eeab059f8057c0b7142",
            "f8c736c90eca43c4a568cdc5abd91539",
            "e5792683addf4da59919a2a261720a08",
            "1810f410a607443e97ae0b78e058285e",
            "4c96cf0c354d434c85ef35ddfbd99611",
            "c175fd78691d4a729f29279ee8f92336"
          ]
        },
        "id": "h_g6zxyEmZqM",
        "outputId": "39a06170-0ac1-47c5-f0a8-d4d4907d02cf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:n04ynq8o) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8725892a81f64a538c20d84c033eec1d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">sweet-durian-10</strong> at: <a href='https://wandb.ai/serena_chan/uncategorized/runs/n04ynq8o' target=\"_blank\">https://wandb.ai/serena_chan/uncategorized/runs/n04ynq8o</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230816_151245-n04ynq8o/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:n04ynq8o). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.8"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230816_151408-nes1e9h8</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/serena_chan/story-generator/runs/nes1e9h8' target=\"_blank\">elated-water-2</a></strong> to <a href='https://wandb.ai/serena_chan/story-generator' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/serena_chan/story-generator' target=\"_blank\">https://wandb.ai/serena_chan/story-generator</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/serena_chan/story-generator/runs/nes1e9h8' target=\"_blank\">https://wandb.ai/serena_chan/story-generator/runs/nes1e9h8</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "99cfeddc6a9c4303a9b2c6d1b5bb513e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='5.954 MB of 5.954 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">elated-water-2</strong> at: <a href='https://wandb.ai/serena_chan/story-generator/runs/nes1e9h8' target=\"_blank\">https://wandb.ai/serena_chan/story-generator/runs/nes1e9h8</a><br/>Synced 4 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230816_151408-nes1e9h8/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Import\n",
        "import wandb\n",
        "\n",
        "model_path = 'cuda-train-50000-epoch-3.pth'\n",
        "\n",
        "# Save your model.\n",
        "torch.save(decoder.state_dict(), model_path)\n",
        "# Save as artifact for version control.\n",
        "run = wandb.init(project='story-generator')\n",
        "artifact = wandb.Artifact('model', type='model')\n",
        "artifact.add_file(model_path)\n",
        "run.log_artifact(artifact)\n",
        "run.finish()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "AJgpAU7knXaU",
        "outputId": "d7dbaac7-2fb7-4b0e-9401-e112cdd0ea6c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.8"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230816_151245-n04ynq8o</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/serena_chan/uncategorized/runs/n04ynq8o' target=\"_blank\">sweet-durian-10</a></strong> to <a href='https://wandb.ai/serena_chan/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/serena_chan/uncategorized' target=\"_blank\">https://wandb.ai/serena_chan/uncategorized</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/serena_chan/uncategorized/runs/n04ynq8o' target=\"_blank\">https://wandb.ai/serena_chan/uncategorized/runs/n04ynq8o</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-cca1e7cc0714>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformerDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Load the state dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    792\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './artifacts/model:v0/cuda-train-50000-epoch-3.pth'"
          ]
        }
      ],
      "source": [
        "#Load\n",
        "import wandb\n",
        "import torch\n",
        "import os\n",
        "\n",
        "run = wandb.init()\n",
        "\n",
        "artifact = run.use_artifact('serena_chan/story-generator/model:v0', type='model')\n",
        "artifact_dir = artifact.download()\n",
        "\n",
        "model_path = os.path.join(artifact_dir, 'cuda-train-50000-epoch-3.pth')\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize your model architecture\n",
        "decoder = TransformerDecoder(vocab_size, d_model).to(device)\n",
        "# Load the state dictionary\n",
        "decoder.load_state_dict(torch.load(model_path))\n",
        "\n",
        "run.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUWkCVigtTXz",
        "outputId": "2c676d92-59e5-441c-e6fb-95f6978b07e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vocab_size 8000\n",
            "Anna and his grandma like to tell ketchup car walls house aloud foot a learn thermometer in fair ear all their knees and watching herself rich squares activities for sweets. Lila stumble and Anna, beg trains, a wheel boil appeared more egg, cart of friends skip around and her in the floor when she pointed there, then they heard them fly sand a thoughtful empty noise of Happylanditail. Molly's dead sounded sour dog poking on there stuck in town stop playing balls! On arrived against many secrets almost had extra cucumber setting wide, salt while until she reached Helen to get a fan curiously, cell. Mrs the neighbourhood tried in front of time itself, butsle whirl curled everywhere he showed it sound. \"Letogit I answer that will be mighty flaps cloud first and buried a trees and watch the Ca suddenNext effort wants to put it on its head mitts examine her own plant onbagsizard saying hello together: okay for shining than town happened,\" Lila flashedfully. They squeezed stayed\n"
          ]
        }
      ],
      "source": [
        "print('vocab_size', vocab_size)\n",
        "\n",
        "temperature = 1.5\n",
        "\n",
        "def temperature_sampling(logits):\n",
        "    # Divide the logits by the temperature\n",
        "    logits = logits / temperature\n",
        "    # Create a distribution\n",
        "    distribution = torch.nn.functional.softmax(logits, dim=-1)\n",
        "    # Sample from the distribution\n",
        "    choice = torch.multinomial(distribution, 1)\n",
        "    token = choice.squeeze().item()\n",
        "    return token\n",
        "\n",
        "def generate_story(model, device, max_length=200):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        input_token = sp.piece_to_id('<s>')\n",
        "        output_sequence = [input_token] # we'll always get the same name because we are using the same model and the same starter token\n",
        "\n",
        "        for i in range(max_length):\n",
        "            input_tensor = torch.tensor([output_sequence]).long().to(device) # Move tensor to the correct device\n",
        "            logit_output = model(input_tensor)\n",
        "\n",
        "            predicted_token = temperature_sampling(logit_output[0, -1, :])\n",
        "\n",
        "            # Break if we predict the end-of-string token\n",
        "            if predicted_token == sp.piece_to_id('</s>'):\n",
        "                break\n",
        "\n",
        "            output_sequence.append(predicted_token)\n",
        "\n",
        "        generated_story= sp.decode_ids(output_sequence[1:])\n",
        "\n",
        "    return generated_story\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "generated_story = generate_story(decoder, device) # Make sure your model is on the correct device\n",
        "print(generated_story)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1810f410a607443e97ae0b78e058285e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25530b3ed760476b842a459408bff602": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25622a07757b454a9b02b4baf201e2ba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30701543fdd6437087e008f0eb0b9178": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25622a07757b454a9b02b4baf201e2ba",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_473ea88059a34441ac518432dc837567",
            "value": 0.09932526294899782
          }
        },
        "4478b438ff024eb3b4e913a046927810": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "473ea88059a34441ac518432dc837567": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4c96cf0c354d434c85ef35ddfbd99611": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55c55702847f4c16963f1a04175cbf55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ed0772ee15c4be995eb9afd1f62669f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b1e30092f33b4150b43762891d7ed475",
              "IPY_MODEL_30701543fdd6437087e008f0eb0b9178"
            ],
            "layout": "IPY_MODEL_9d45f30a410d41d2bc6e71ba4ec0bfec"
          }
        },
        "6b385ef65bfe4eeab059f8057c0b7142": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c96cf0c354d434c85ef35ddfbd99611",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c175fd78691d4a729f29279ee8f92336",
            "value": 0.9985994099832624
          }
        },
        "6c1a67da60834a748ced4aac4887702d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b0fe0f5e41a47d98b92fff0b833f513": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8725892a81f64a538c20d84c033eec1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5013a329b524d4ab70eec3d410daca5",
              "IPY_MODEL_b6dee90914fd4aecac4dfba8a3f721e8"
            ],
            "layout": "IPY_MODEL_93e9ba02298941d2b6cd44f443d10d8c"
          }
        },
        "93e9ba02298941d2b6cd44f443d10d8c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99cfeddc6a9c4303a9b2c6d1b5bb513e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b4690013074e4f07a4ea1630c719d38e",
              "IPY_MODEL_6b385ef65bfe4eeab059f8057c0b7142"
            ],
            "layout": "IPY_MODEL_f8c736c90eca43c4a568cdc5abd91539"
          }
        },
        "9d45f30a410d41d2bc6e71ba4ec0bfec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1e30092f33b4150b43762891d7ed475": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c1a67da60834a748ced4aac4887702d",
            "placeholder": "​",
            "style": "IPY_MODEL_25530b3ed760476b842a459408bff602",
            "value": "0.001 MB of 0.010 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "b4690013074e4f07a4ea1630c719d38e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5792683addf4da59919a2a261720a08",
            "placeholder": "​",
            "style": "IPY_MODEL_1810f410a607443e97ae0b78e058285e",
            "value": "5.954 MB of 5.963 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "b6dee90914fd4aecac4dfba8a3f721e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_beba080cfc9c4da3a896bd4f2afc1a92",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_55c55702847f4c16963f1a04175cbf55",
            "value": 0.11652627356598476
          }
        },
        "beba080cfc9c4da3a896bd4f2afc1a92": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c175fd78691d4a729f29279ee8f92336": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d5013a329b524d4ab70eec3d410daca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4478b438ff024eb3b4e913a046927810",
            "placeholder": "​",
            "style": "IPY_MODEL_7b0fe0f5e41a47d98b92fff0b833f513",
            "value": "0.001 MB of 0.010 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "e5792683addf4da59919a2a261720a08": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8c736c90eca43c4a568cdc5abd91539": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
