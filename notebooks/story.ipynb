{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yRu7IOs4hsh",
        "outputId": "e0791cd3-8cd5-4c3f-e976-97bf8ad7c1d9"
      },
      "outputs": [],
      "source": [
        "!pip -q install datasets\n",
        "!pip -q install sentencepiece\n",
        "!pip -q install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsh_axMLnqsY",
        "outputId": "b675d82e-699f-49b4-e4c5-33248594dd00"
      },
      "outputs": [],
      "source": [
        "%pip install wandb\n",
        "!wandb login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsvsYVGF4OHF",
        "outputId": "2d034a1d-b0c7-4881-b4ac-f79bee4d7bc5"
      },
      "outputs": [],
      "source": [
        "# Data\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns  # makes heatmap look better\n",
        "from datasets import load_dataset\n",
        "import sentencepiece as spm\n",
        "import os\n",
        "\n",
        "vocab_size = 7600 # english has 26 * 2 + punctuation\n",
        "\n",
        "dataset = load_dataset(\"roneneldan/TinyStories\")\n",
        "\n",
        "train_dataset = dataset['train'][:50000]\n",
        "\n",
        "validation_dataset = dataset['validation'][:50000]\n",
        "text_data = [entry for entry in train_dataset['text']]\n",
        "validation_data = [entry for entry in validation_dataset['text']]\n",
        "\n",
        "text_data_str = '\\n'.join(text_data)\n",
        "with open('temp.txt', 'w', encoding='utf-8') as f:\n",
        "    f.write(text_data_str)\n",
        "\n",
        "spm.SentencePieceTrainer.train(\n",
        "        f'--input=temp.txt --model_prefix=stories --vocab_size={vocab_size} --character_coverage=1.0 --model_type=unigram'\n",
        "    )\n",
        "sp = spm.SentencePieceProcessor(model_file='./stories.model')\n",
        "\n",
        "print('successfully trained sp')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUdtO0ij47pZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.optim import Adam\n",
        "from collections import Counter\n",
        "import json\n",
        "\n",
        "PAD_TOKEN = sp.piece_to_id('<unk>')\n",
        "batch_size = 16\n",
        "\n",
        "def target_story_to_tensor(story):\n",
        "    tokens = torch.tensor(sp.encode_as_ids(story) + [sp.piece_to_id('</s>')], dtype=torch.long)\n",
        "    return tokens\n",
        "\n",
        "def input_story_to_tensor(story):\n",
        "    tokens = torch.tensor([sp.piece_to_id('<s>')] + sp.encode_as_ids(story), dtype=torch.long)\n",
        "    return tokens\n",
        "\n",
        "class StoryDataset(Dataset):\n",
        "    def __init__(self, stories):\n",
        "        self.stories = stories\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.stories)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        story = self.stories[idx]\n",
        "        return input_story_to_tensor(story), target_story_to_tensor(story)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    inputs, targets = zip(*batch)\n",
        "    inputs = pad_sequence(inputs, batch_first=True, padding_value=PAD_TOKEN)\n",
        "    targets = pad_sequence(targets, batch_first=True, padding_value=PAD_TOKEN)\n",
        "    return inputs, targets\n",
        "\n",
        "# Create dataset and dataloader\n",
        "dataset = StoryDataset(text_data)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "val_data = StoryDataset(validation_data)\n",
        "val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFjr-EAr4Q4l",
        "outputId": "cd28a234-0b0f-44cd-d7ca-bcd5635af1bc"
      },
      "outputs": [],
      "source": [
        "print(len(text_data))\n",
        "print(len(validation_data))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NK3oHTvI5RqC",
        "outputId": "04d3d7cd-d2d6-425f-a406-20a81d981daf"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "d_model = 64\n",
        "dropout = 0.1 # 10% chance that any given neuron will be dropped out\n",
        "n_heads = 8\n",
        "n_layer = 8\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fr6ZPtcC5SRo"
      },
      "outputs": [],
      "source": [
        "def create_mask(seq):\n",
        "    seq_len = seq.size(1)\n",
        "    mask = torch.triu(torch.ones(seq_len, seq_len, device=seq.device), diagonal=1).bool()\n",
        "    return mask\n",
        "\n",
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model):\n",
        "        super(TransformerDecoder, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_encoder = PositionalEncoding(d_model)\n",
        "\n",
        "        self.blocks = nn.Sequential(\n",
        "            *[Block(n_heads) for _ in range(n_layer)]\n",
        "        )\n",
        "        self.fc = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # print('Im here')\n",
        "        input = self.embedding(input)\n",
        "        input = self.pos_encoder(input)\n",
        "        blocks_output = self.blocks(input)\n",
        "\n",
        "        logits = self.fc(blocks_output)\n",
        "        return logits\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, n_heads):\n",
        "        super().__init__()\n",
        "        head_size = d_model // n_heads\n",
        "        self.multi_head_attention = MultiHeadAttention(n_heads, head_size)\n",
        "        self.ffwd = nn.Sequential(\n",
        "            nn.Linear(d_model, 4*d_model), # expanding and contracting the model for it to learn more intricate patterns\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(4*d_model, d_model)\n",
        "        )\n",
        "\n",
        "        self.ln1 = nn.LayerNorm(d_model)\n",
        "        self.ln2 = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # actually doing residual connection here by attn1_output + input\n",
        "        # print('im in block forward')\n",
        "        x = x + self.multi_head_attention(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        # print('Block shape', x.shape)\n",
        "        return x\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([SelfAttention(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(d_model, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mask = create_mask(x).to(x.device)\n",
        "        # print('im in multiheadattention')\n",
        "        out = torch.cat([h(x, x, x, mask) for h in self.heads], dim=-1) # can parallelize it\n",
        "        # print('multiheadattention out.shape', out.shape)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        # here not printing\n",
        "        # print('dropout out.shape', out.shape)\n",
        "        return out\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, head_size):\n",
        "        super(SelfAttention, self).__init__()\n",
        "        self.query = nn.Linear(d_model, head_size, bias=False)\n",
        "        self.key = nn.Linear(d_model, head_size, bias=False)\n",
        "        self.value = nn.Linear(d_model, head_size, bias=False)\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        # print('im in self attention')\n",
        "        # print('head_size')\n",
        "        q = self.query(query)\n",
        "        k = self.key(key)\n",
        "        v = self.value(value)\n",
        "\n",
        "        # print('q.shape', q.shape)\n",
        "        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_model)\n",
        "        # print('scores.shape', scores.shape)\n",
        "        # print('mask', mask)\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask, float('-inf'))\n",
        "\n",
        "        attention_weights = torch.nn.functional.softmax(scores, dim=-1)\n",
        "        # print('attention_weights', attention_weights.shape)\n",
        "        # print('v', v.shape)\n",
        "        output = torch.matmul(attention_weights, v)\n",
        "        # print('output.shape of selfattention', output.shape)\n",
        "        return output\n",
        "\n",
        "def plot_attention(attention, source_seq, target_seq):\n",
        "    \"\"\"\n",
        "    Plots the attention weights.\n",
        "    :param attention: Attention weights matrix.\n",
        "    :param source_seq: Source sequence tokens.\n",
        "    :param target_seq: Target sequence tokens.\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(5, 5))\n",
        "    sns.heatmap(attention, cmap='viridis', xticklabels=source_seq, yticklabels=target_seq)\n",
        "    plt.xlabel('Keys (Source)')\n",
        "    plt.ylabel('Queries (Target)')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578,
          "referenced_widgets": [
            "fd28418933a1493ba195ea8e0b829287",
            "658085af61cd4900b23893db2520a16f",
            "25152397c222454b9e5d225087f7ff78",
            "b75b76b57b7e441e92490f34b3fdee2f",
            "d2c6e7676b0b4cfd8bec0fc271c307ad",
            "0188c987fea84df38e071df7de5032d4",
            "7c94cfcbc38a42f2bc16b1cf77c7e539",
            "09ff7ddea6a3409493f3c3d79dc8075b"
          ]
        },
        "id": "NxjQ62ud5T7r",
        "outputId": "407bda2f-7b4d-4973-9d36-99a0bf7d8b02"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "import time\n",
        "\n",
        "num_epochs = 3\n",
        "lr = 0.0001\n",
        "\n",
        "name = \"experiment-3\"\n",
        "\n",
        "# Define the model, optimizer, and loss\n",
        "decoder = TransformerDecoder(vocab_size, d_model).to(device)\n",
        "optimizer = Adam(decoder.parameters(), lr=lr)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "num_params = sum(p.numel() for p in decoder.parameters())\n",
        "\n",
        "# Training loop\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss(ignore_index=PAD_TOKEN)\n",
        "\n",
        "run = wandb.init(project=\"story_generator\", name=name,\n",
        "                 config={\"optimizer\": \"Adam\", \"lr\": lr, \"epochs\": num_epochs, \"batch_size\": batch_size, \"vocab_size\": vocab_size, \"n_heads\": n_heads, \"n_layer\": n_layer, \"d_model\": d_model, \"num_params\": num_params})\n",
        "\n",
        "wandb.watch(decoder)\n",
        "\n",
        "\n",
        "train_iteration = 0\n",
        "val_iteration = 0\n",
        "for epoch in range(num_epochs):\n",
        "    decoder.train()\n",
        "    total_loss = 0.0\n",
        "    # start_time = time.time()\n",
        "    for inputs, targets in dataloader:\n",
        "        start_time = time.time()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        outputs = decoder(inputs)\n",
        "        torch.cuda.empty_cache()\n",
        "        loss = criterion(outputs.view(-1, vocab_size), targets.view(-1))\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        train_iteration += 1\n",
        "\n",
        "        if train_iteration % 1000 == 0:\n",
        "          avg_loss = total_loss / 1000\n",
        "          end_time = time.time()\n",
        "          iteration_duration = (end_time - start_time) * 1000\n",
        "          wandb.log({\"iteration\": train_iteration, \"train_loss\": avg_loss, \"time_taken\": iteration_duration})\n",
        "          total_loss = 0.0\n",
        "\n",
        "    # end_time = time.time()  # <-- Record the end time\n",
        "    # epoch_duration = end_time - start_time  # <-- Calculate epoch duration\n",
        "\n",
        "    # avg_loss = total_loss / len(dataloader)\n",
        "    # print(f\"Epoch {epoch + 1}/{num_epochs} - Loss: {avg_loss:.4f}\")\n",
        "    # wandb.log({\"epoch\": epoch, \"train_loss\": avg_loss, \"time_taken\": epoch_duration})\n",
        "\n",
        "\n",
        "    # validation loop\n",
        "    decoder.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "      for val_inputs, val_targets in val_dataloader:\n",
        "        start_time = time.time()\n",
        "        val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
        "        val_outputs = decoder(val_inputs)\n",
        "        loss = criterion(outputs.view(-1, vocab_size), targets.view(-1))\n",
        "        val_loss += loss.item()\n",
        "\n",
        "        val_iteration += 1\n",
        "        if val_iteration % 1000 == 0:\n",
        "          avg_loss = val_loss / 1000\n",
        "          end_time = time.time()\n",
        "          iteration_duration = (end_time - start_time) * 1000\n",
        "          wandb.log({\"iteration\": val_iteration, \"val_loss\": avg_loss, \"time_taken\": iteration_duration})\n",
        "          val_loss = 0.0\n",
        "\n",
        "    # avg_val_loss = val_loss / len(val_dataloader)\n",
        "    # wandb.log({\"epoch\": epoch, \"val_loss\": avg_loss, \"time_taken\": epoch_duration})\n",
        "\n",
        "\n",
        "# Save your model.\n",
        "model_path = f'cuda-train-50000-{name}.pth'\n",
        "\n",
        "wandb.log({\"num_params\": num_params})\n",
        "torch.save(decoder.state_dict(), model_path)\n",
        "artifact = wandb.Artifact('model', type='model')\n",
        "artifact.add_file(model_path)\n",
        "run.log_artifact(artifact)\n",
        "run.finish()\n",
        "\n",
        "\n",
        "# torch.save(decoder.state_dict(), model_path)\n",
        "# wandb.save(model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAEu94EjNr7T",
        "outputId": "3f8b37dd-f713-4ef7-ffaf-9fa63d879c30"
      },
      "outputs": [],
      "source": [
        "print('vocab_size', vocab_size)\n",
        "\n",
        "def generate_story(model, device, max_length=200):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        input_token = sp.piece_to_id('<s>')\n",
        "        output_sequence = [input_token] # we'll always get the same name because we are using the same model and the same starter token\n",
        "\n",
        "        for i in range(max_length):\n",
        "            input_tensor = torch.tensor([output_sequence]).long().to(device) # Move tensor to the correct device\n",
        "            logit_output = model(input_tensor)\n",
        "\n",
        "            softmax = nn.Softmax(dim=-1)\n",
        "            softmax_output = softmax(logit_output)\n",
        "            # Taking the token with the highest probability for prediction\n",
        "            predicted_token = softmax_output[0, -1, :].argmax().item()\n",
        "\n",
        "            # Break if we predict the end-of-string token\n",
        "            if predicted_token == sp.piece_to_id('</s>'):\n",
        "                break\n",
        "\n",
        "            output_sequence.append(predicted_token)\n",
        "\n",
        "        # Convert token IDs back to strings\n",
        "        print(output_sequence[1:])\n",
        "        generated_story= sp.decode_ids(output_sequence[1:])\n",
        "\n",
        "    return generated_story\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "generated_story = generate_story(decoder.to(device), device) # Make sure your model is on the correct device\n",
        "print(generated_story)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407,
          "referenced_widgets": [
            "8725892a81f64a538c20d84c033eec1d",
            "d5013a329b524d4ab70eec3d410daca5",
            "b6dee90914fd4aecac4dfba8a3f721e8",
            "93e9ba02298941d2b6cd44f443d10d8c",
            "4478b438ff024eb3b4e913a046927810",
            "7b0fe0f5e41a47d98b92fff0b833f513",
            "beba080cfc9c4da3a896bd4f2afc1a92",
            "55c55702847f4c16963f1a04175cbf55",
            "99cfeddc6a9c4303a9b2c6d1b5bb513e",
            "b4690013074e4f07a4ea1630c719d38e",
            "6b385ef65bfe4eeab059f8057c0b7142",
            "f8c736c90eca43c4a568cdc5abd91539",
            "e5792683addf4da59919a2a261720a08",
            "1810f410a607443e97ae0b78e058285e",
            "4c96cf0c354d434c85ef35ddfbd99611",
            "c175fd78691d4a729f29279ee8f92336"
          ]
        },
        "id": "h_g6zxyEmZqM",
        "outputId": "39a06170-0ac1-47c5-f0a8-d4d4907d02cf"
      },
      "outputs": [],
      "source": [
        "# Import\n",
        "import wandb\n",
        "\n",
        "model_path = 'cuda-train-50000-epoch-3.pth'\n",
        "\n",
        "# Save your model.\n",
        "torch.save(decoder.state_dict(), model_path)\n",
        "# Save as artifact for version control.\n",
        "run = wandb.init(project='story-generator')\n",
        "artifact = wandb.Artifact('model', type='model')\n",
        "artifact.add_file(model_path)\n",
        "run.log_artifact(artifact)\n",
        "run.finish()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "AJgpAU7knXaU",
        "outputId": "d7dbaac7-2fb7-4b0e-9401-e112cdd0ea6c"
      },
      "outputs": [],
      "source": [
        "#Load\n",
        "import wandb\n",
        "import torch\n",
        "import os\n",
        "\n",
        "run = wandb.init()\n",
        "\n",
        "artifact = run.use_artifact('serena_chan/story-generator/model:v0', type='model')\n",
        "artifact_dir = artifact.download()\n",
        "\n",
        "model_path = os.path.join(artifact_dir, 'cuda-train-50000-epoch-3.pth')\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize your model architecture\n",
        "decoder = TransformerDecoder(vocab_size, d_model).to(device)\n",
        "# Load the state dictionary\n",
        "decoder.load_state_dict(torch.load(model_path))\n",
        "\n",
        "run.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUWkCVigtTXz",
        "outputId": "2c676d92-59e5-441c-e6fb-95f6978b07e6"
      },
      "outputs": [],
      "source": [
        "print('vocab_size', vocab_size)\n",
        "\n",
        "temperature = 1.5\n",
        "\n",
        "def temperature_sampling(logits):\n",
        "    # Divide the logits by the temperature\n",
        "    logits = logits / temperature\n",
        "    # Create a distribution\n",
        "    distribution = torch.nn.functional.softmax(logits, dim=-1)\n",
        "    # Sample from the distribution\n",
        "    choice = torch.multinomial(distribution, 1)\n",
        "    token = choice.squeeze().item()\n",
        "    return token\n",
        "\n",
        "def generate_story(model, device, max_length=200):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        input_token = sp.piece_to_id('<s>')\n",
        "        output_sequence = [input_token] # we'll always get the same name because we are using the same model and the same starter token\n",
        "\n",
        "        for i in range(max_length):\n",
        "            input_tensor = torch.tensor([output_sequence]).long().to(device) # Move tensor to the correct device\n",
        "            logit_output = model(input_tensor)\n",
        "\n",
        "            predicted_token = temperature_sampling(logit_output[0, -1, :])\n",
        "\n",
        "            # Break if we predict the end-of-string token\n",
        "            if predicted_token == sp.piece_to_id('</s>'):\n",
        "                break\n",
        "\n",
        "            output_sequence.append(predicted_token)\n",
        "\n",
        "        generated_story= sp.decode_ids(output_sequence[1:])\n",
        "\n",
        "    return generated_story\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "generated_story = generate_story(decoder, device) # Make sure your model is on the correct device\n",
        "print(generated_story)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0188c987fea84df38e071df7de5032d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09ff7ddea6a3409493f3c3d79dc8075b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1810f410a607443e97ae0b78e058285e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25152397c222454b9e5d225087f7ff78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c94cfcbc38a42f2bc16b1cf77c7e539",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_09ff7ddea6a3409493f3c3d79dc8075b",
            "value": 0.998802218731682
          }
        },
        "4478b438ff024eb3b4e913a046927810": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c96cf0c354d434c85ef35ddfbd99611": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55c55702847f4c16963f1a04175cbf55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "658085af61cd4900b23893db2520a16f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2c6e7676b0b4cfd8bec0fc271c307ad",
            "placeholder": "​",
            "style": "IPY_MODEL_0188c987fea84df38e071df7de5032d4",
            "value": "7.304 MB of 7.313 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "6b385ef65bfe4eeab059f8057c0b7142": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c96cf0c354d434c85ef35ddfbd99611",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c175fd78691d4a729f29279ee8f92336",
            "value": 0.9985994099832624
          }
        },
        "7b0fe0f5e41a47d98b92fff0b833f513": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c94cfcbc38a42f2bc16b1cf77c7e539": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8725892a81f64a538c20d84c033eec1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5013a329b524d4ab70eec3d410daca5",
              "IPY_MODEL_b6dee90914fd4aecac4dfba8a3f721e8"
            ],
            "layout": "IPY_MODEL_93e9ba02298941d2b6cd44f443d10d8c"
          }
        },
        "93e9ba02298941d2b6cd44f443d10d8c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99cfeddc6a9c4303a9b2c6d1b5bb513e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b4690013074e4f07a4ea1630c719d38e",
              "IPY_MODEL_6b385ef65bfe4eeab059f8057c0b7142"
            ],
            "layout": "IPY_MODEL_f8c736c90eca43c4a568cdc5abd91539"
          }
        },
        "b4690013074e4f07a4ea1630c719d38e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5792683addf4da59919a2a261720a08",
            "placeholder": "​",
            "style": "IPY_MODEL_1810f410a607443e97ae0b78e058285e",
            "value": "5.954 MB of 5.963 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "b6dee90914fd4aecac4dfba8a3f721e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_beba080cfc9c4da3a896bd4f2afc1a92",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_55c55702847f4c16963f1a04175cbf55",
            "value": 0.11652627356598476
          }
        },
        "b75b76b57b7e441e92490f34b3fdee2f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "beba080cfc9c4da3a896bd4f2afc1a92": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c175fd78691d4a729f29279ee8f92336": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d2c6e7676b0b4cfd8bec0fc271c307ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5013a329b524d4ab70eec3d410daca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4478b438ff024eb3b4e913a046927810",
            "placeholder": "​",
            "style": "IPY_MODEL_7b0fe0f5e41a47d98b92fff0b833f513",
            "value": "0.001 MB of 0.010 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "e5792683addf4da59919a2a261720a08": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8c736c90eca43c4a568cdc5abd91539": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd28418933a1493ba195ea8e0b829287": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_658085af61cd4900b23893db2520a16f",
              "IPY_MODEL_25152397c222454b9e5d225087f7ff78"
            ],
            "layout": "IPY_MODEL_b75b76b57b7e441e92490f34b3fdee2f"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
